{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-vector multiplication multiply with transpose matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through how to implement $ y := A^T x + y $ <i> without explicitly transposing the matrix</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some functions that are part of our laff library (of which this function will become a part) as well as some routines from the FLAME API (Application Programming Interface) that allows us to write code that closely resembles how we typeset algorithms using the FLAME notation.  These functions are imported with the \"import laff\" and \"import flame\" statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (via dot products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/431Mvmult_n_unb_var1.png\" alt=\"Matrix-vector multiplication via dot products algorithm\" width=\"48%\"><image src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/431Mvmult_t_unb_var1.png\" alt=\"Matrix-vector multiplication via dot products algorithm\" width=\"48%\">\n",
    "\n",
    "\n",
    "Above, you find two algorithms.  The one on the left computes $ y := A x + y $ via dot products and the one on the right computes $ y := A^T x + y $ via dot products.  You are to implement the one on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The routine <br> <code> Mvmult_t_unb_var1( A, x, y ) </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine, given $ A \\in \\mathbb{R}^{m \\times m} $, $ x \\in \\mathbb{R}^m $, and $ y \\in \\mathbb{R}^m $, computes $ y := A^T x + y $.  The \"_t_\" in the name of the routine indicates this is the \"transpose\" matrix-vector multiplication.  \n",
    "\n",
    "The specific laff functions we will use are \n",
    "<ul>\n",
    "<li> <code> laff.dots( x, y, alpha ) </code> which computes $ \\alpha := x^T y + \\alpha $.  </li>\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flame\n",
    "import laff as laff\n",
    "\n",
    "def Mvmult_t_unb_var1(A, x, y):\n",
    "\n",
    "    AL, AR = flame.part_1x2(A, \\\n",
    "                            0, 'LEFT')\n",
    "\n",
    "    yT, \\\n",
    "    yB  = flame.part_2x1(y, \\\n",
    "                         0, 'TOP')\n",
    "\n",
    "    while AL.shape[1] < A.shape[1]:\n",
    "\n",
    "        A0, a1, A2 = flame.repart_1x2_to_1x3(AL, AR, \\\n",
    "                                             1, 'RIGHT')\n",
    "\n",
    "        y0,   \\\n",
    "        psi1, \\\n",
    "        y2    = flame.repart_2x1_to_3x1(yT, \\\n",
    "                                        yB, \\\n",
    "                                        1, 'BOTTOM')\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.dots(a1, x, psi1)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        AL, AR = flame.cont_with_1x3_to_1x2(A0, a1, A2, \\\n",
    "                                            'LEFT')\n",
    "\n",
    "        yT, \\\n",
    "        yB  = flame.cont_with_3x1_to_2x1(y0,   \\\n",
    "                                         psi1, \\\n",
    "                                         y2,   \\\n",
    "                                         'TOP')\n",
    "\n",
    "    flame.merge_2x1(yT, \\\n",
    "                    yB, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly test the routine by creating a 3 x 4 matrix and related vectors, performing the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A before =\n",
      "[[0.65172132 0.55823012 0.8617082  0.25669227]\n",
      " [0.94794816 0.56053487 0.10085845 0.86007394]\n",
      " [0.06848067 0.02485671 0.65976334 0.87826993]]\n",
      "x before =\n",
      "[[0.79915422]\n",
      " [0.48516732]\n",
      " [0.55825869]]\n",
      "y before =\n",
      "[[0.53069318]\n",
      " [0.51464584]\n",
      " [0.55118804]\n",
      " [0.78559288]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from numpy import matrix\n",
    "\n",
    "A = matrix( random.rand( 3,4 ) )\n",
    "x = matrix( random.rand( 3,1 ) )\n",
    "y = matrix( random.rand( 4,1 ) )\n",
    "yold = matrix( random.rand( 4,1 ) )\n",
    "\n",
    "print( 'A before =' )\n",
    "print( A )\n",
    "\n",
    "print( 'x before =' )\n",
    "print( x )\n",
    "\n",
    "print( 'y before =' )\n",
    "print( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y after =\n",
      "[[1.54966242]\n",
      " [1.24658747]\n",
      " [1.65707762]\n",
      " [1.89831117]]\n",
      "y - ( transpose( A ) * x + yold ) = \n",
      "[[-2.22044605e-16]\n",
      " [-2.22044605e-16]\n",
      " [ 2.22044605e-16]\n",
      " [ 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import transpose\n",
    "\n",
    "laff.copy( y, yold )   # save the original vector y\n",
    "\n",
    "Mvmult_t_unb_var1( A, x, y )\n",
    "\n",
    "print( 'y after =' )\n",
    "print( y )\n",
    "\n",
    "print( 'y - ( transpose( A ) * x + yold ) = ' )\n",
    "print( y - ( transpose( A ) * x + yold ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, it seems to work!  (Notice that we are doing floating point computations, which means that due to rounding you may not get an exact \"0\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch your code in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (via <code>axpy</code>s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/431Mvmult_n_unb_var2.png\" alt=\"Matrix-vector multiplication via axpys algorithm\" width=\"55%\"><image src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/431Mvmult_t_unb_var2.png\" alt=\"Matrix-vector multiplication via dot axpys algorithm\" width=\"45%\">\n",
    "\n",
    "Above, you find two algorithms.  The one on the left computes $ y := A x + y $ via <code> axpy</code>s and the one on the right computes $ y := A^T x + y $ via <code> axpy</code>s.  You are to implement the one on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The routine <br> <code> Mvmult_t_unb_var2( A, x, y ) </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine, given $ A \\in \\mathbb{R}^{m \\times m} $, $ x \\in \\mathbb{R}^m $, and $ y \\in \\mathbb{R}^m $, computes $ y := A^T x + y $.  The \"_t_\" in the name of the routine indicates this is the \"transpose\" matrix-vector multiplication.  \n",
    "\n",
    "The specific laff functions we will use are \n",
    "<ul>\n",
    "<li> <code> laff.axpy( alpha, x, y ) </code> which computes $ y := \\alpha x + y $.  </li>\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mvmult_t_unb_var2(A, x, y):\n",
    "\n",
    "    AT, \\\n",
    "    AB  = flame.part_2x1(A, \\\n",
    "                         0, 'TOP')\n",
    "\n",
    "    xT, \\\n",
    "    xB  = flame.part_2x1(x, \\\n",
    "                         0, 'TOP')\n",
    "\n",
    "    while AT.shape[0] < A.shape[0]:\n",
    "\n",
    "        A0,  \\\n",
    "        a1t, \\\n",
    "        A2   = flame.repart_2x1_to_3x1(AT, \\\n",
    "                                       AB, \\\n",
    "                                       1, 'BOTTOM')\n",
    "\n",
    "        x0,   \\\n",
    "        chi1, \\\n",
    "        x2    = flame.repart_2x1_to_3x1(xT, \\\n",
    "                                        xB, \\\n",
    "                                        1, 'BOTTOM')\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.axpy(chi1, a1t, y)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        AT, \\\n",
    "        AB  = flame.cont_with_3x1_to_2x1(A0,  \\\n",
    "                                         a1t, \\\n",
    "                                         A2,  \\\n",
    "                                         'TOP')\n",
    "\n",
    "        xT, \\\n",
    "        xB  = flame.cont_with_3x1_to_2x1(x0,   \\\n",
    "                                         chi1, \\\n",
    "                                         x2,   \\\n",
    "                                         'TOP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly test the routine by creating a 3 x 4 matrix and related vectors, performing the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A before =\n",
      "[[0.09588204]\n",
      " [0.40930986]\n",
      " [0.98037535]\n",
      " [0.10177008]]\n",
      "x before =\n",
      "[[0.50673859]\n",
      " [0.03164391]\n",
      " [0.60130129]]\n",
      "y before =\n",
      "[[0.09588204]\n",
      " [0.40930986]\n",
      " [0.98037535]\n",
      " [0.10177008]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from numpy import matrix\n",
    "\n",
    "A = matrix( random.rand( 3,4 ) )\n",
    "x = matrix( random.rand( 3,1 ) )\n",
    "y = matrix( random.rand( 4,1 ) )\n",
    "yold = matrix( random.rand( 4,1 ) )\n",
    "\n",
    "print( 'A before =' )\n",
    "print( y )\n",
    "\n",
    "print( 'x before =' )\n",
    "print( x )\n",
    "\n",
    "print( 'y before =' )\n",
    "print( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y after =\n",
      "[[0.52890576]\n",
      " [1.22869051]\n",
      " [1.43746968]\n",
      " [0.86256279]]\n",
      "y - ( transpose( A ) * x + yold ) = \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import transpose\n",
    "\n",
    "laff.copy( y, yold )   # save the original vector y\n",
    "\n",
    "Mvmult_t_unb_var2( A, x, y )\n",
    "\n",
    "print( 'y after =' )\n",
    "print( y )\n",
    "\n",
    "print( 'y - ( transpose( A ) * x + yold ) = ' )\n",
    "print( y - ( transpose( A ) * x + yold ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, it seems to work!  (Notice that we are doing floating point computations, which means that due to rounding you may not get an exact \"0\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch your code in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
